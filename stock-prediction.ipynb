{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":433077,"sourceType":"datasetVersion","datasetId":195545}],"dockerImageVersionId":30066,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\n\n# For reading stock data from yahoo\nfrom pandas_datareader.data import DataReader\n\n# For time stamps\nfrom datetime import datetime\n#date time to get the date and time for the prediction","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using data of apple google microsoft and amazon\ntech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n# Set up End and Start times for data grab\nend = datetime.now()\nstart = datetime(end.year - 1, end.month, end.day)\n#end time is todays date and start time is from last\n\n#For loop for grabing yahoo finance data and setting as a dataframe\nfor stock in tech_list:   \n    # Set DataFrame as the Stock Ticker\n    globals()[stock] = DataReader(stock, 'yahoo', start, end)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"company_list = [AAPL, GOOG, MSFT, AMZN]\ncompany_name = [\"APPLE\", \"GOOGLE\", \"MICROSOFT\", \"AMAZON\"]\n\nfor company, com_name in zip(company_list, company_name):\n    company[\"company_name\"] = com_name\n    \ndf = pd.concat(company_list, axis=0)\ndf.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AAPL.describe()\n# SUMMARY STATS FOR APPLE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AMZN.describe()\n# SUMMARY STATS FOR AMAZON","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# APPLE INFO\nAAPL.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HISTORICAL VIEW OF EACH COMPANY\nplt.figure(figsize=(12, 8))\nplt.subplots_adjust(top=1.25, bottom=1.2)\nplt.subplot(2, 2, 1)\ncompany['Adj Close'].plot()\nplt.ylabel('Adj Close')\nplt.xlabel(None)\nplt.title(f\"{AMZN}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HISTORICAL VIEW OF adj CLOSING PRICE FOR ALL THE TECH COMPANIES\n# The closing price is the raw price, which is just the cash value of the last transacted price before the market closes.\n# The adjusted closing price factors in anything that might affect the stock price after the market closes.\n# final closing price after some affects \nplt.figure(figsize=(12, 8))\nplt.subplots_adjust(top=1.25, bottom=1.2)\n\nfor i, company in enumerate(company_list, 1):\n    plt.subplot(2, 2, i)\n    company['Adj Close'].plot()\n    plt.ylabel('Adj Close')\n    plt.xlabel('YEAR-MONTH')\n    plt.title(f\"{tech_list[i - 1]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HISTORICAL VIEW OF TOTAL VOLUME OF STOCK BEING TRADED EACH DAY FOR ALL THE TECH COMPANIES\n# Volume is the number of shares of a security traded during a given period of time.\n# volume measures the number of a stock's shares that are traded on a stock exchange in a day or a period of time. \n# Volume is important because it confirms trend directions. ... When a stock's price and volume increase,\n# it indicates the buying interest in the stock. It shows the stock's uptrend\nplt.figure(figsize=(12, 8))\nplt.subplots_adjust(top=1.25, bottom=1.2)\n\nfor i, company in enumerate(company_list, 1):\n    plt.subplot(2, 2, i)\n    company['Volume'].plot()\n    plt.ylabel('VOLUME')\n    plt.xlabel('YEAR-MONTH')\n    plt.title(f\"{tech_list[i - 1]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we've seen the close price and volume traded each day, now ill calculate the moving average for the stock\n\n","metadata":{}},{"cell_type":"code","source":"# A simple moving average (SMA) is a calculation that takes the arithmetic mean of a given set of prices over the specific number of days in the past; for example,\n# over the previous 15, 30, 100, or 200 days.\n#lets take moving average for 10 20 and 50 days\nma_day = [10, 20, 50]\nfor ma in ma_day:\n    for company in company_list:\n        column_name = f\"MA for {ma} days\"\n        company[column_name] = company['Adj Close'].rolling(ma).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(AMZN.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's go ahead and plot all the additional Moving Averages\ndf.groupby(\"company_name\").hist( bins=25, grid=False,figsize=(10, 10),color='#86bf91');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\nAAPL[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,0])\naxes[0,0].set_title('APPLE')\n\nGOOG[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[0,1])\naxes[0,1].set_title('GOOGLE')\n\nMSFT[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,0])\naxes[1,0].set_title('MICROSOFT')\n\nAMZN[['Adj Close', 'MA for 10 days', 'MA for 20 days', 'MA for 50 days']].plot(ax=axes[1,1])\naxes[1,1].set_title('AMAZON')\n\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  In order to analyze the risk of the stock we'll need to take a closer look at the daily changes of the stock, and not just its absolute value.\n**The average return is the simple mathematical average of a series of returns generated over a specified period of time.\nThe average return can help measure the past performance of a security or portfolio.**\n","metadata":{}},{"cell_type":"code","source":"# We'll use pct_change to find the percent change for each day\n# Pandas dataframe.pct_change() function calculates the percentage change between the current and a prior element.\n# This function by default calculates the percentage change from the immediately previous row.\nfor company in company_list:\n    company['Daily Return'] = company['Adj Close'].pct_change()\n# Then we'll plot the daily return percentage\nfig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_figheight(8)\nfig.set_figwidth(15)\n#for apple\nAAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\naxes[0,0].set_title('APPLE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for all the companies\nfor company in company_list:\n    company['Daily Return'] = company['Adj Close'].pct_change()\n\n# Then we'll plot the daily return percentage\nfig, axes = plt.subplots(nrows=2, ncols=2)\nfig.set_figheight(8)\nfig.set_figwidth(15)\n\nAAPL['Daily Return'].plot(ax=axes[0,0], legend=True, linestyle='--', marker='o')\naxes[0,0].set_title('APPLE')\n\nGOOG['Daily Return'].plot(ax=axes[0,1], legend=True, linestyle='--', marker='o')\naxes[0,1].set_title('GOOGLE')\n\nMSFT['Daily Return'].plot(ax=axes[1,0], legend=True, linestyle='--', marker='o')\naxes[1,0].set_title('MICROSOFT')\n\nAMZN['Daily Return'].plot(ax=axes[1,1], legend=True, linestyle='--', marker='o')\naxes[1,1].set_title('AMAZON')\n\nfig.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A kernel density estimate (KDE) plot is a method for visualizing the distribution of observations in a dataset,\n# analagous to a histogram. KDE represents the data using a continuous probability \n# density curve in one or more dimensions\nplt.figure(figsize=(12, 12))\n\n# for i, company in enumerate(company_list, 1):\n#     plt.subplot(2, 2, i)\n#     sns.distplot(company['Daily Return'].dropna(), bins=100, color='purple')\n#     plt.ylabel('Daily Return')\n#     plt.title(f'{company_name[i - 1]}')\n# Could have also done:\nAAPL['Daily Return'].hist()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\n\nfor i, company in enumerate(company_list, 1):\n    plt.subplot(2, 2, i)\n    sns.distplot(company['Daily Return'].dropna(), bins=100, color='purple')\n    plt.ylabel('Daily Return')\n    plt.title(f'{company_name[i - 1]}')\n# Could have also done:\n# AAPL['Daily Return'].hist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What was the correlation between different stocks closing prices?**\nNow what if we wanted to analyze the returns of all the stocks in our list? Let's go ahead and build a DataFrame with all the ['Close'] columns for each of the stocks dataframes","metadata":{}},{"cell_type":"code","source":"# Grab all the closing prices for the tech stock list into one DataFrame\nclosing_df = DataReader(tech_list, 'yahoo', start, end)['Adj Close']\n\n# Let's take a quick look\nclosing_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now that we have all the closing prices, let's go ahead and get the daily return for all the stocks,\n# Make a new tech returns DataFrame\ntech_rets = closing_df.pct_change()\ntech_rets.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rets = tech_rets.dropna()\n\narea = np.pi*20\n\nplt.figure(figsize=(12, 10))\nplt.scatter(rets.mean(), rets.std(), s=area)\nplt.xlabel('Expected return')\nplt.ylabel('Risk')\n\nfor label, x, y in zip(rets.columns, rets.mean(), rets.std()):\n    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', \n                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Predicting the closing price stock price of APPLE inc:******","metadata":{}},{"cell_type":"code","source":"df = DataReader('AAPL', data_source='yahoo', start='2012-01-01', end=datetime.now())\n# Show teh data\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if we want more data then change the start year \nplt.figure(figsize=(16,8))\nplt.title('Close Price History')\nplt.plot(df['Close'])\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe with only the 'Close column \ndata = df.filter(['Close'])\n# Convert the dataframe to a numpy array\ndataset = data.values\n# Get the number of rows to train the model on\ntraining_data_len = int(np.ceil( len(dataset) * .95 ))\n\ntraining_data_len\n#if we want more rows then change the start year ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"now we'll use Scikit-learn,that is probably the most useful library for machine learning in Python. The sklearn library contains a lot of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction.\n","metadata":{}},{"cell_type":"code","source":"# Transform features by scaling each feature to a given range. \n# This estimator scales and translates each feature individually such that it is in the given range on the training set,\n# e.g. between zero and one\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\n\nscaled_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the training data set \n# Create the scaled training data set\ntrain_data = scaled_data[0:int(training_data_len), :]\n# Split the data into x_train and y_train data sets\nx_train = []\ny_train = []\n\nfor i in range(60, len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i, 0])\n    if i<= 61:\n        print(x_train)\n        print(y_train)\n        print()\n        \n# Convert the x_train and y_train to numpy arrays \nx_train, y_train = np.array(x_train), np.array(y_train)\n\n# Reshape the data\nx_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n# x_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM\n\n# Build the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape= (x_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(25))\nmodel.add(Dense(1))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit(x_train, y_train, batch_size=1, epochs=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the testing data set\n# Create a new array containing scaled values \nimport math\ntest_data = scaled_data[training_data_len - 60: , :]\n# Create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:, :]\nfor i in range(60, len(test_data)):\n    x_test.append(test_data[i-60:i, 0])\n    \n# Convert the data to a numpy array\nx_test = np.array(x_test)\n\n# Reshape the data\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n\n# Get the models predicted price values \npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)\n\n# Get the root mean squared error (RMSE)\nrmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n# mse = np.square(np.subtract(predictions,y_test)).mean()\n# rmse = math.sqrt(mse)\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n# Visualize the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price USD ($)', fontsize=18)\nplt.plot(train['Close'])\nplt.plot(valid[['Close', 'Predictions']])\nplt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show the valid and predicted prices\nvalid\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}